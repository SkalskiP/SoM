[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SkalskiP/SoM/blob/master/unofficial_som_demo.ipynb)

# Set-of-Mark (SoM)

## üëã hello

This is a non-official (and probably much worse) implementation of the Set-of-Mark 
(SoM) tools described in the paper ["Set-of-Mark Prompting Unleashes Extraordinary 
Visual Grounding in GPT-4V"](https://arxiv.org/abs/2310.11441) by Jianwei Yang, Hao 
Zhang, Feng Li, Xueyan Zou, Chunyuan Li, Jianfeng Gao.

## üõ†Ô∏è how it works?

Run Google Colab with an unofficial SoM implementation. Load your image and select 
the appropriate `MIN_AREA_PERCENTAGE` and `MAX_AREA_PERCENTAGE` values to label 
the objects of interest.

![image (28)](https://github.com/SkalskiP/SoM/assets/26109316/51934c68-4929-456a-9e4a-e958c9e72574)

## üìç roadmap

- [ ] Wrap up the current SoM implementation in the Gradio app.

## ü¶∏ contribution

We would love your help in making this repository even better! If you have done some 
cool experiment that you would like to share, or if you have any suggestions for 
improvement, feel free to open an [issue](https://github.com/SkalskiP/SoM/issues) or 
submit a [pull request](https://github.com/SkalskiP/SoM/pulls).
